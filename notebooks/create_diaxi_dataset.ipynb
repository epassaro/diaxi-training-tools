{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del dataset DIAxI en formato COCO\n",
    "\n",
    "## 1. Solucionar problemas con el *encoding* de los archivos\n",
    "\n",
    "Un problema con el que nos encontramos es que tanto el escaneo del archivo de Abuelas como el etiquetado colaborativo fue realizado en distintos sistemas operativos que utilizan diferentes tipos de *encoding* para el nombre de los archivos. Para poder construir el dataset tratamos de convertir todo a UTF-8 conservando la mayor cantidad de archivos posible.\n",
    "\n",
    "> - Requiere instalar `convmv` en la distribución GNU/Linux.\n",
    "> - Se asume que los archivos JSON se encuentran en la carpeta `jsons` y el archivo completo de imágenes en `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# convmv -f UTF-8 -t ISO-8859-1 -r jsons --fixdouble --notest\n",
    "# convmv -f ISO-8859-1 -t UTF-8 -r jsons --notest\n",
    "# convmv -f UTF-8 -t ISO-8859-1 -r dataset --fixdouble --notest\n",
    "# convmv -f ISO-8859-1 -t UTF-8 -r dataset --notest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Luego para cada archivo JSON se copia su correspondiente archivo TIFF a la carpeta `fixed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "os.makedirs(\"fixed/images\", exist_ok=True)\n",
    "os.makedirs(\"fixed/jsons\", exist_ok=True)\n",
    "\n",
    "lost = []\n",
    "for j in os.listdir(\"jsons\"):\n",
    "    img = j.replace(\".json\", \".tif\")\n",
    "\n",
    "    try:\n",
    "        copyfile(f\"dataset/{img}\", f\"fixed/images/{img}\")\n",
    "        copyfile(f\"jsons/{j}\", f\"fixed/jsons/{j}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        lost.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lost)  # Perdimos 51 archivos en el camino :("
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Enderezado de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from deskew import determine_skew\n",
    "\n",
    "THRESHOLD = 10  # límite de 10 grados\n",
    "\n",
    "def rotate(image: np.ndarray, angle: float, background: Union[int, Tuple[int, int, int]]) -> np.ndarray:\n",
    "    old_width, old_height = image.shape[:2]\n",
    "    angle_radian = math.radians(angle)\n",
    "    width = abs(np.sin(angle_radian) * old_height) + abs(np.cos(angle_radian) * old_width)\n",
    "    height = abs(np.sin(angle_radian) * old_width) + abs(np.cos(angle_radian) * old_height)\n",
    "\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    rot_mat[1, 2] += (width - old_width) / 2\n",
    "    rot_mat[0, 2] += (height - old_height) / 2\n",
    "    \n",
    "    return cv2.warpAffine(image, rot_mat, (int(round(height)), int(round(width))), borderValue=background)\n",
    "\n",
    "for i in os.listdir(\"fixed/images/\"):\n",
    "    image = cv2.imread(f\"fixed/images/{i}\")\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    angle = determine_skew(grayscale)\n",
    "\n",
    "    if abs(angle) < THRESHOLD:\n",
    "        rotated = rotate(image, angle, (0, 0, 0))\n",
    "        cv2.imwrite(f\"fixed/images/{i}\", rotated)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creación del archivo JSON principal\n",
    "\n",
    "El formato COCO (*Common Objects in Context*) consta de un archivo JSON y un directorio de imágenes. Vamos a construir el archivo JSON de acuerdo a las especificaciones del formato, que es bastante simple y sólo consta de 4 llaves: `images`, `categories`, `annotations` e `info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "jsons = sorted(os.listdir(\"fixed/jsons\"))\n",
    "tiffs = sorted(os.listdir(\"fixed/images\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hacemos verificamos si todos los JSONs tienen una imagen que les corresponda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tiffs)):\n",
    "    assert jsons[i].replace(\".json\", \".tif\") == tiffs[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la llave `info` con metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\"contributor\": \"Lionel Messi\",\n",
    "        \"date_created\": \"2022-12-18 10:10:10.101010\",\n",
    "        \"description\": \"\",\n",
    "        \"url\": \"\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2023\n",
    "       }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la llave `annotations`.\n",
    "\n",
    "Para ello leemos cada archivo JSON y buscamos recursivamente todas las llaves que tengan el nombre `bounding_box`. El nombre de la llave que esté por encima de cada *bounding box* será el nombre de la *clase* (`category_id`) a la que pertenece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_generator(json_input, lookup_key, parent_key=None):\n",
    "    if isinstance(json_input, dict):\n",
    "        for k, v in json_input.items():\n",
    "            if k == lookup_key:\n",
    "                yield parent_key, v\n",
    "\n",
    "            else:\n",
    "                yield from item_generator(v, lookup_key, k)\n",
    "\n",
    "    elif isinstance(json_input, list):\n",
    "        for i, item in enumerate(json_input):\n",
    "            if isinstance(item, (dict, list)):\n",
    "                for result in item_generator(item, lookup_key, parent_key=f\"{parent_key}\"):\n",
    "                    yield result\n",
    "\n",
    "            elif item == lookup_key:\n",
    "                yield parent_key, item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "annotations = []\n",
    "\n",
    "keys = [\"Diario\", \"Fecha\", \"Notas\", \"Página\", \"Copete\", \"Cuerpo\", \"Destacado\", \"Epígrafe\", \"Firma\", \"Fotografía\", \"Título\", \"Volanta\"]\n",
    "class2id = dict(zip((keys), range(len(keys))))\n",
    "\n",
    "for i,j in enumerate(jsons):\n",
    "    # `images` key\n",
    "    img = {}\n",
    "    im = Image.open(f\"fixed/images/{tiffs[i]}\")\n",
    "    w, h = im.size\n",
    "\n",
    "    img[\"id\"] = i\n",
    "    img[\"file_name\"] = f\"images/{tiffs[i]}\"\n",
    "    img[\"width\"] = w\n",
    "    img[\"height\"] = h\n",
    "    images.append(img)\n",
    "\n",
    "    # `annotations` key\n",
    "    with open(f\"fixed/jsons/{j}\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        gen = item_generator(data, \"bounding_box\")\n",
    "        for g in gen:\n",
    "            try:\n",
    "                cid = class2id[g[0]]\n",
    "\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                x, y, w, h = g[1].values()\n",
    "\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            ann = { \"area\": w*h,\n",
    "                    \"bbox\": [x, y, w, h],\n",
    "                    \"category_id\": cid,\n",
    "                    \"id\": 0,\n",
    "                    \"ignore\": 0,\n",
    "                    \"image_id\": i,\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"segmentation\": [[x, y, x+w, y, x+w, y+h, x, y+h]],\n",
    "                }\n",
    "\n",
    "            annotations.append(ann)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enumeramos las anotaciones entre `0..N`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for ann in annotations:\n",
    "    ann[\"id\"] = n\n",
    "    n += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la llave `categories`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [{\"id\": v, \"name\": k} for (k,v) in class2id.items()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosotros consideramos que el nombre `Imagen` es más adecuado que `Fotografía`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories[9][\"name\"] = \"Imagen\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente guardamos el resultado en un nuevo archivo JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\"images\": images, \n",
    "          \"categories\": categories, \n",
    "          \"annotations\": annotations, \n",
    "          \"info\": info\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fixed/result.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtrar clases (opcional)\n",
    "\n",
    "Utilizamos el script `catfilter.py` para conservar las anotaciones pertenecientes al subconjunto de clases que queremos usar en nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "python scripts/catfilter.py -i fixed/result.json -o fixed/result_filtered.json -c 'Copete,Cuerpo,Destacado,Epígrafe,Imagen,Título,Volanta'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Descartar imágenes\n",
    "\n",
    "Posteriormente se guardan las imágenes anotadas con `pyodi` y se procede a una inspección ocular de los resultados. Posteriormente se borran a mano las imágenes cuyas *bounding boxes* no coinciden con los elementos que pretenden localizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pyodi paint-annotations fixed/result_filtered.json fixed fixed/painted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualizamos el archivo JSON para descartar las imágenes que no pasaron el filtro \"humano\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ok = [f\"images/{i}\".replace(\"_result.tif\", \".tif\") for i in sorted(os.listdir(\"fixed/painted\"))]\n",
    "\n",
    "with open(\"fixed/result_filtered.json\", \"r\") as f:\n",
    "    filtered = json.load(f)\n",
    "\n",
    "final_images = []\n",
    "for img in filtered[\"images\"]:\n",
    "    if img[\"file_name\"] in img_ok:\n",
    "        final_images.append(img)\n",
    "\n",
    "filtered[\"images\"] = final_images\n",
    "\n",
    "with open(\"fixed/result_final.json\", \"w\") as f:\n",
    "    json.dump(filtered, f, indent=2, sort_keys=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fusionar datasets (opcional)\n",
    "\n",
    "Con `pyodi` se pueden fusionar distintos sets de datos en formato COCO. Pero primero es necesario arreglar los JSON para mapear las IDs de las imágenes entre `0..N`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# python scripts/imgidfix.py -i <archivo json> <archivo json de salida>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# pyodi coco merge <archivo json 1> <archivo json 2> <archivo json de salida>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comprimir el set de datos\n",
    "\n",
    "Finalmente comprimimos el set de datos para su distribución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p dataset-diaxi-coco\n",
    "cp -r fixed/images dataset-diaxi-coco\n",
    "cp fixed/result_final.json dataset-diaxi-coco/result.json\n",
    "cd dataset-diaxi-coco\n",
    "zip -r ../dataset-diaxi-coco.zip images result.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diaxi-training-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
