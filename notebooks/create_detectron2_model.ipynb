{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0drTrtG62LG"
      },
      "source": [
        "# Instalación\n",
        "\n",
        "Las herramientas necesarias para entrenar el modelo se obtienen de nuestro repositorio `diaxi-training-tools`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpm-8QPv7Uvw"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "rm -rf tools\n",
        "git clone -q 'https://github.com/epassaro/diaxi-training-tools' tools\n",
        "pip install -q -r tools/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **ADVERTENCIA:** se va a reiniciar el entorno de ejecución, es normal, ignorar los mensajes de error y continuar ejecutando el resto de la notebook."
      ],
      "metadata": {
        "id": "2UH5OTNpDLfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "XuVeya7-3Lxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFjszuHb7QIf"
      },
      "source": [
        "<br>\n",
        "\n",
        "# Probando el modelo `PrimaLayout`\n",
        "\n",
        "Elegimos el modelo [`PrimaLayout`](https://layout-parser.readthedocs.io/en/latest/notes/modelzoo.html#model-catalog) como punto de partida para hacer *transfer learning* por estar entrenado con un set de datos de imágenes de diarios y revistas.  Es un modelo tipo [Mask R-CNN](https://wiki.math.uwaterloo.ca/statwiki/index.php?title=Mask_RCNN) y fue hecho con la librería de [**Detectron2**](https://github.com/facebookresearch/detectron2) de Facebook AI.\n",
        "\n",
        "<br>\n",
        "\n",
        "Vamos a descargar la configuración y los pesos del modelo para ver como se desempeña."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aT6ufsI6tTH"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mkdir -p model\n",
        "curl -sL 'https://www.dropbox.com/s/yc92x97k50abynt/config.yaml?dl=1' -o model/config.yaml\n",
        "curl -sL 'https://www.dropbox.com/s/h7th27jfv19rxiy/model_final.pth?dl=1' -o model/model_final.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZMCEkGsgV2B"
      },
      "source": [
        "<br>\n",
        "\n",
        "Leemos la configuración y a creamos un objeto de la clase `DefaultPredictor`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-GoQsQw6wWo"
      },
      "outputs": [],
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"model/config.yaml\")\n",
        "cfg.MODEL.WEIGHTS = \"model/model_final.pth\"\n",
        "\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YatpVg43isFs"
      },
      "source": [
        "<br>\n",
        "\n",
        "Descargamos una imagen de prueba y procedemos a hacer la inferencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOEwgl5A6v1P"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "curl -sL 'https://www.lavoz.com.ar/resizer/xuZbQG2Eksz9cu5TUO-h725zcPI=/1023x1428/smart/cloudfront-us-east-1.images.arcpublishing.com/grupoclarin/LFOKK4SCLNDPHGITAJ35EGKWKE.jpg' -o sample_data/image.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kDkAUo_7wsy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "\n",
        "image = cv2.imread(\"sample_data/image.jpg\")\n",
        "metadata = MetadataCatalog.get(\"prima_layout\")\n",
        "metadata.thing_classes = [\"UnknownClass\", \"TextRegion\", \"ImageRegion\", \"TableRegion\", \"MathsRegion\", \"SeparatorRegion\", \"OtherRegion\"]\n",
        "\n",
        "v = Visualizer(image[:, :, ::-1],\n",
        "               metadata=metadata,\n",
        "               scale=0.5,\n",
        "               instance_mode=ColorMode.IMAGE_BW\n",
        "              )\n",
        "\n",
        "output = predictor(image)\n",
        "out = v.draw_instance_predictions(output[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GE45a1ki4VN"
      },
      "source": [
        "<br>\n",
        "\n",
        "El resultado es muy bueno. Ahora queremos reentrenarlo para que detecte las clases de nuestro problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXgY3FaTjjKC"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "# Reentrenando el modelo\n",
        "\n",
        "Para reentrenar el modelo utilizamos un dataset de 497 imágenes en formato [COCO](https://cocodataset.org/). Del total de imágenes, 297 provienen de la fase de etiquetado colaborativo, mientras que 200 fueron agregadas por nosotros posteriormente para aumentar el tamaño de la muestra.\n",
        "\n",
        "Además, se calcularon las *máscaras de segmentación* que el modelo requiere, entre varios cambios que fue necesario hacer para ajustarse al formato requerido.\n",
        "\n",
        "<br>\n",
        "\n",
        "> *Para ver los detalles de la creación del dataset referirse al [repositorio de entrenamiento](https://github.com/epassaro/diaxi-training-tools).*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2znZl79j00n"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "rm -rf dataset dataset-diaxi-coco.zip\n",
        "curl -sL 'http://xmm-newton.fcaglp.unlp.edu.ar/assets/dataset-diaxi-coco497.zip' -o dataset-diaxi-coco.zip\n",
        "unzip -q dataset-diaxi-coco.zip -d dataset && rm dataset-diaxi-coco.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSQSsoLBllnS"
      },
      "source": [
        "<br>\n",
        "\n",
        "Ahora dividimos en set de entrenamiento (85%) y validación (15%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7qhSCWVllsF"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pyodi coco random-split dataset/result.json dataset/result --val-percentage 0.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klhu9mBLl50w"
      },
      "source": [
        "<br>\n",
        "\n",
        "Y los registramos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA80lfq2l229"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "\n",
        "register_coco_instances(\"diaxi_train\", {}, \"dataset/result_train.json\", \"dataset\")\n",
        "register_coco_instances(\"diaxi_val\", {}, \"dataset/result_val.json\", \"dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp10yknImj2p"
      },
      "source": [
        "<br>\n",
        "\n",
        "Hacemos los cambios necesarios en la configuración del modelo para hacer *transfer learning*:\n",
        "\n",
        "- Partir desde los pesos y la configuración del modelo anterior\n",
        "- Setear el número máximo de iteraciones\n",
        "- Setear el número de iteraciones entre cada llamado al evaluador\n",
        "- Setear el número de iteraciones entre cada *checkpoint*\n",
        "- Ajustar el número de clases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C9C_-UNmCo7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"model/config.yaml\")\n",
        "cfg.MODEL.WEIGHTS = \"model/model_final.pth\"\n",
        "cfg.DATASETS.TRAIN = (\"diaxi_train\",)\n",
        "cfg.DATASETS.TEST = (\"diaxi_val\",)\n",
        "cfg.OUTPUT_DIR = \"output\"\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 5000\n",
        "cfg.SOLVER.STEPS = []\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 200\n",
        "cfg.TEST.EVAL_PERIOD = 200\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7\n",
        "\n",
        "_ = os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaTWIIOUm5v-"
      },
      "source": [
        "<br>\n",
        "\n",
        "Creamos la clase `CustomTrainer` y agregamos el código necesario para llamar al evaluador."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.data import DatasetMapper, build_detection_train_loader\n",
        "from detectron2.data import transforms as T\n",
        "\n",
        "class CustomTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "        return COCOEvaluator(\"diaxi_val\", cfg, True, output_folder)\n",
        "\n",
        "    # No hay suficiente VRAM para hacer data augmentation :()\n",
        "    # def build_train_loader(cls, cfg):\n",
        "    #     mapper = DatasetMapper(cfg, is_train=True, augmentations=[T.RandomFlip(prob=0.5, horizontal=True, vertical=False)])\n",
        "    #     return build_detection_train_loader(cfg, mapper=mapper)"
      ],
      "metadata": {
        "id": "KSkyO-M0PXhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "Iniciamos el *dashboard* de Tensorflow para monitorear la evolución de la métrica y entrenamos el modelo."
      ],
      "metadata": {
        "id": "Q-A87z8sgOwn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sZPHW2-nBSO"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output/inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eNorHbKm0EF"
      },
      "outputs": [],
      "source": [
        "trainer = CustomTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "Luego de examinar cuidadosamente las métricas en *TensorBoard*, guardamos el modelo que vamos a implementar en el software. En nuestro caso elegimos el *checkpoint* de 2600 iteraciones."
      ],
      "metadata": {
        "id": "GjqmpHxAqWBi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSw-Wf2Sp4x9"
      },
      "outputs": [],
      "source": [
        "with open(\"output/config.yaml\", \"w\") as f:\n",
        "   f.write(trainer.cfg.dump())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "mkdir -p download\n",
        "cp output/config.yaml download/\n",
        "cp output/metrics.json download/\n",
        "cp output/model_0002599.pth download/model_final.pth"
      ],
      "metadata": {
        "id": "gJJWcbF0utGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"download/config.yaml\")\n",
        "cfg.MODEL.WEIGHTS = \"https://github.com/epassaro/diaxi-training-tools/releases/download/v0.1/model_final.pth\"\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8\n",
        "cfg.MODEL.DEVICE = \"cpu\"\n",
        "\n",
        "# Sobreescribimos\n",
        "with open(\"download/config.yaml\", \"w\") as f:\n",
        "   f.write(cfg.dump())"
      ],
      "metadata": {
        "id": "lD8oYapEqks8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "tar -zcvf model_final.tar.gz model_final"
      ],
      "metadata": {
        "id": "Lo8uiGInsRpV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}