{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del dataset DIAxI en formato COCO\n",
    "\n",
    "## 1. Arreglamos el *encoding* de los archivos\n",
    "\n",
    "Un problema con el que nos encontramos es que tanto el escaneo del archivo de Abuelas como el etiquetado colaborativo fue realizado en distintos sistemas operativos con diferentes tipos de *encoding*. Para poder construir el dataset tratamos de convertir todo a UTF-8 y conservar la mayor cantidad posible de archivos.\n",
    "\n",
    "> - Requiere instalar `convmv` en la distribución GNU/Linux.\n",
    "> - Se asume que los archivos JSON del etiquetado colaborativo se encuentran en la carpeta `jsons` y el archivo completo de imágenes en `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# convmv -f UTF-8 -t ISO-8859-1 -r jsons --fixdouble --notest\n",
    "# convmv -f ISO-8859-1 -t UTF-8 -r jsons --notest\n",
    "# convmv -f UTF-8 -t ISO-8859-1 -r dataset --fixdouble --notest\n",
    "# convmv -f ISO-8859-1 -t UTF-8 -r dataset --notest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Luego para cada archivo JSON se copia su correspondiente archivo TIFF a la carpeta `fixed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "os.makedirs(\"fixed/images\", exist_ok=True)\n",
    "os.makedirs(\"fixed/jsons\", exist_ok=True)\n",
    "\n",
    "lost = []\n",
    "for j in os.listdir(\"jsons\"):\n",
    "    img = j.replace(\".json\", \".tif\")\n",
    "\n",
    "    try:\n",
    "        copyfile(f\"dataset/{img}\", f\"fixed/images/{img}\")\n",
    "        copyfile(f\"jsons/{j}\", f\"fixed/jsons/{j}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        lost.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lost)  # Perdimos 51 archivos en el camino :("
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Enderezar las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from deskew import determine_skew\n",
    "\n",
    "THRESHOLD = 10  # límite de 10 grados\n",
    "\n",
    "def rotate(image: np.ndarray, angle: float, background: Union[int, Tuple[int, int, int]]) -> np.ndarray:\n",
    "    old_width, old_height = image.shape[:2]\n",
    "    angle_radian = math.radians(angle)\n",
    "    width = abs(np.sin(angle_radian) * old_height) + abs(np.cos(angle_radian) * old_width)\n",
    "    height = abs(np.sin(angle_radian) * old_width) + abs(np.cos(angle_radian) * old_height)\n",
    "\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    rot_mat[1, 2] += (width - old_width) / 2\n",
    "    rot_mat[0, 2] += (height - old_height) / 2\n",
    "    \n",
    "    return cv2.warpAffine(image, rot_mat, (int(round(height)), int(round(width))), borderValue=background)\n",
    "\n",
    "for i in os.listdir(\"fixed/images/\"):\n",
    "    image = cv2.imread(f\"fixed/images/{i}\")\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    angle = determine_skew(grayscale)\n",
    "\n",
    "    if abs(angle) < THRESHOLD:\n",
    "        rotated = rotate(image, angle, (0, 0, 0))\n",
    "        cv2.imwrite(f\"fixed/images/{i}\", rotated)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construimos el archivo JSON principal\n",
    "\n",
    "El formato COCO (*Common Objects in Context*) consta de un archivo JSON y un directorio de imágenes. Vamos a construir el archivo JSON de acuerdo a las especificaciones del formato, es bastante simple y sólo consta de 4 llaves: `images`, `categories`, `annotations` e `info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "jsons = sorted(os.listdir(\"fixed/jsons\"))\n",
    "tiffs = sorted(os.listdir(\"fixed/images\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hacemos un chequeo para verificar si todos los JSONs tienen una imagen que les corresponda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tiffs)):\n",
    "    assert jsons[i].replace(\".json\", \".tif\") == tiffs[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la llave `info` con metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\"contributor\": \"Lionel Messi\",\n",
    "        \"date_created\": \"2022-12-18 10:10:10.101010\",\n",
    "        \"description\": \"\",\n",
    "        \"url\": \"\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2023\n",
    "       }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la llave `annotations`.\n",
    "\n",
    "Para ello leemos cada archivo JSON y buscamos recursivamente todas las llaves que tenga el nombre `bounding_box`. El nombre de la llave que esté por encima de cada *bounding box* nos dará el nombre de la *clase* (`category_id`) a la que pertenece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_generator(json_input, lookup_key, parent_key=None):\n",
    "    if isinstance(json_input, dict):\n",
    "        for k, v in json_input.items():\n",
    "            if k == lookup_key:\n",
    "                yield parent_key, v\n",
    "\n",
    "            else:\n",
    "                yield from item_generator(v, lookup_key, k)\n",
    "\n",
    "    elif isinstance(json_input, list):\n",
    "        for i, item in enumerate(json_input):\n",
    "            if isinstance(item, (dict, list)):\n",
    "                for result in item_generator(item, lookup_key, parent_key=f\"{parent_key}\"):\n",
    "                    yield result\n",
    "\n",
    "            elif item == lookup_key:\n",
    "                yield parent_key, item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "annotations = []\n",
    "\n",
    "keys = [\"Diario\", \"Fecha\", \"Notas\", \"Página\", \"Copete\", \"Cuerpo\", \"Destacado\", \"Epígrafe\", \"Firma\", \"Fotografía\", \"Título\", \"Volanta\"]\n",
    "class2id = dict(zip((keys), range(len(keys))))\n",
    "\n",
    "for i,j in enumerate(jsons):\n",
    "    # `images` key\n",
    "    img = {}\n",
    "    im = Image.open(f\"fixed/images/{tiffs[i]}\")\n",
    "    w, h = im.size\n",
    "\n",
    "    img[\"id\"] = i\n",
    "    img[\"file_name\"] = f\"images/{tiffs[i]}\"\n",
    "    img[\"width\"] = w\n",
    "    img[\"height\"] = h\n",
    "    images.append(img)\n",
    "\n",
    "    # `annotations` key\n",
    "    with open(f\"fixed/jsons/{j}\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        gen = item_generator(data, \"bounding_box\")\n",
    "        for g in gen:\n",
    "            try:\n",
    "                cid = class2id[g[0]]\n",
    "\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                x, y, w, h = g[1].values()\n",
    "\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            ann = { \"area\": w*h,\n",
    "                    \"bbox\": [x, y, w, h],\n",
    "                    \"category_id\": cid,\n",
    "                    \"id\": 0,\n",
    "                    \"ignore\": 0,\n",
    "                    \"image_id\": i,\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"segmentation\": [[x, y, x+w, y, x+w, y+h, x, y+h]],\n",
    "                }\n",
    "\n",
    "            annotations.append(ann)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enumeramos las anotaciones de `0..N`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for ann in annotations:\n",
    "    ann[\"id\"] = n\n",
    "    n += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la llave `categories` que es muy simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [{\"id\": v, \"name\": k} for (k,v) in class2id.items()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos que el nombre `Imagen` es más adecuado que `Fotografía`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories[9][\"name\"] = \"Imagen\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente guardamos el resultado en un nuevo archivo JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\"images\": images, \n",
    "          \"categories\": categories, \n",
    "          \"annotations\": annotations, \n",
    "          \"info\": info\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fixed/result.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtrar clases (opcional)\n",
    "\n",
    "Utilizamos el script `catfilter.py` para conservar solamente las anotaciones referidas al subconjunto de clases que queremos usar en nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "python scripts/catfilter.py -i fixed/result.json -o fixed/result_filtered.json -c 'Copete,Cuerpo,Destacado,Epígrafe,Imagen,Título,Volanta'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Descartar imágenes\n",
    "\n",
    "Posteriormente se guardan las imágenes anotadas con `pyodi` y se procede a una inspección ocular de los resultados. **Se borran a mano** las imágenes cuyas *bounding boxes* no coinciden con los elementos que pretenden localizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pyodi paint-annotations fixed/result_filtered.json fixed fixed/painted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualizamos el archivo JSON para incluir solamente las imágenes que pasaron el filtro humano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ok = [f\"images/{i}\".replace(\"_result.tif\", \".tif\") for i in sorted(os.listdir(\"fixed/painted\"))]\n",
    "\n",
    "with open(\"fixed/result_filtered.json\", \"r\") as f:\n",
    "    filtered = json.load(f)\n",
    "\n",
    "final_images = []\n",
    "for img in filtered[\"images\"]:\n",
    "    if img[\"file_name\"] in img_ok:\n",
    "        final_images.append(img)\n",
    "\n",
    "filtered[\"images\"] = final_images\n",
    "\n",
    "with open(\"fixed/result_final.json\", \"w\") as f:\n",
    "    json.dump(filtered, f, indent=2, sort_keys=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fusionar datasets (opcional)\n",
    "\n",
    "Con `pyodi` se pueden fusionar distintos sets de datos en formato COCO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# pyodi coco merge coco_1.json coco_2.json output.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comprimir el set de datos\n",
    "\n",
    "Finalmente comprimimos el set de datos para su distribución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p dataset-diaxi-coco\n",
    "cp -r fixed/images dataset-diaxi-coco\n",
    "cp fixed/result_final.json dataset-diaxi-coco/result.json\n",
    "cd dataset-diaxi-coco\n",
    "zip -r ../dataset-diaxi-coco.zip images result.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diaxi-training-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
